{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from torch.utils.data import Dataset, DataLoader, Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data from .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify year interval for training data\n",
    "init_year = 2018\n",
    "end_year = 2024 # inclusive\n",
    "\n",
    "df_list = []\n",
    "for year in range(init_year, end_year + 1):\n",
    "    df = pd.read_csv(f'../data/Prepared data/{str(year)}_features.csv')\n",
    "    df_list.append(df)\n",
    "del df\n",
    "df_raw = pd.concat(df_list, axis=0, ignore_index=True)\n",
    "df = df_raw[['timestamp', 'load', 'temp', 'year', 'month', 'day', 'hour', 'minute']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Day Type (weekday, weekend, holiday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import holidays\n",
    "\n",
    "def is_workday(date:datetime.date):\n",
    "    \"\"\"\n",
    "    Determines the type of day (workday or not) for a given date.\n",
    "\n",
    "    Args:\n",
    "        date (datetime.date): The date to check.\n",
    "\n",
    "    Returns:\n",
    "        int: 1 if workday else 0.\n",
    "    \"\"\"\n",
    "    us_holidays = holidays.US()\n",
    "\n",
    "    if date in us_holidays:\n",
    "        return 0\n",
    "\n",
    "    if date.weekday() >= 5:  # Saturday is 5, Sunday is 6\n",
    "        return 0\n",
    "\n",
    "    return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "\n",
    "class TimestampTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "\n",
    "        X['timestamp'] = pd.to_datetime(X['timestamp'])\n",
    "        X['is_workday'] = X['timestamp'].apply(is_workday)\n",
    "        # X['year'] = X['timestamp'].dt.year\n",
    "        # X['month'] = X['timestamp'].dt.month\n",
    "        # X['day'] = X['timestamp'].dt.day\n",
    "        # X['hour'] = X['timestamp'].dt.hour\n",
    "        # X['minute'] = X['timestamp'].dt.minute\n",
    "        # X = X.drop('timestamp', axis=1)\n",
    "        return X\n",
    "    \n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, df, seq_len, pred_len):\n",
    "        \"\"\"\n",
    "        Custom Dataset for multivariate time series.\n",
    "\n",
    "        Args:\n",
    "            df (pd.Dataframe): Assume the dataframe has been preprocessed and has only numeriacal values.\n",
    "            seq_length (int): Length of each sequence.\n",
    "            transform: Composition of transformations.\n",
    "        \"\"\"\n",
    "        super(TimeSeriesDataset, self).__init__()\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.features = self.df.values\n",
    "        self.targets = self.df['load'].values\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.features) - self.seq_len - self.pred_len + 1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.features[idx:idx + self.seq_len, :]\n",
    "        sequence = torch.tensor(sequence, dtype=torch.float32)\n",
    "        \n",
    "        target = self.targets[idx + self.seq_len: idx + self.seq_len + self.pred_len]\n",
    "        target = torch.tensor(target, dtype=torch.float32)\n",
    "        \n",
    "        return sequence, target\n",
    "\n",
    "class Preprocessor():\n",
    "    def __init__(self):\n",
    "        self.timestamp_transformer = TimestampTransformer()\n",
    "        self.imputer_load = SimpleImputer(strategy='mean')\n",
    "        self.imputer_temp = SimpleImputer(strategy='mean')\n",
    "        \n",
    "        self.load_mean = None\n",
    "        self.load_std  = None\n",
    "        self.temp_mean = None\n",
    "        self.temp_std  = None\n",
    "        self.feature_cols = ['load', 'temp', 'is_workday', 'year', 'month', 'day', 'hour', 'minute']\n",
    "\n",
    "    def fit(self, df):\n",
    "\n",
    "        self.imputer_load.fit(df[['load']])\n",
    "        self.imputer_temp.fit(df[['temp']])\n",
    "\n",
    "        self.load_mean = df['load'].mean()\n",
    "        self.load_std  = df['load'].std()\n",
    "        self.temp_mean = df['temp'].mean()\n",
    "        self.temp_std  = df['temp'].std()\n",
    "\n",
    "    def transform(self, df):\n",
    "\n",
    "        df = self.timestamp_transformer.transform(df)\n",
    "\n",
    "        df['load'] = self.imputer_load.transform(df[['load']])\n",
    "        df['temp'] = self.imputer_temp.transform(df[['temp']])\n",
    "\n",
    "        df['load'] = (df['load'] - self.load_mean) / self.load_std\n",
    "        df['temp'] = (df['temp'] - self.temp_mean) / self.temp_std\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def inverse_transform(self, df):\n",
    "        \n",
    "        df['load'] = df['load'] * self.load_std + self.load_mean\n",
    "        df['temp'] = df['temp'] * self.temp_std + self.temp_mean\n",
    "\n",
    "        return df\n",
    "\n",
    "    def fit_transform(self, df):\n",
    "        self.fit(df)\n",
    "        df_out = self.transform(df)\n",
    "        return df_out\n",
    "\n",
    "def create_dataset_splits(df_all, input_seq_len, output_seq_len, batch_size):\n",
    "\n",
    "    df_all = df_all.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "    df_no_test = df_all[df_all['year'] != 2024].copy().reset_index(drop=True) # exclude 2024 test data\n",
    "\n",
    "    preprocessor = Preprocessor()\n",
    "    df_no_test = preprocessor.fit_transform(df_no_test)\n",
    "\n",
    "    # train dataset: 2018-2022\n",
    "    # validation datset: 2023\n",
    "    # test dataset: 2024\n",
    "    df_train = df_no_test[(df_no_test['year'] >= 2018) & (df_no_test['year'] <= 2022)].copy().reset_index(drop=True)\n",
    "    df_val = df_no_test[df_no_test['year'] == 2023].copy().reset_index(drop=True)\n",
    "\n",
    "    df_train = df_train.drop('timestamp', axis=1)\n",
    "    df_val = df_val.drop('timestamp', axis=1)\n",
    "\n",
    "    train_dataset = TimeSeriesDataset(df_train, input_seq_len, output_seq_len)\n",
    "    val_dataset  = TimeSeriesDataset(df_val, input_seq_len, output_seq_len)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, pin_memory_device='cuda')\n",
    "    val_loader  = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, pin_memory_device='cuda')\n",
    "\n",
    "    return train_loader, val_loader, preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, preprocessor = create_dataset_splits(df, 288, 288, 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, num_features, output_size, hidden_size, num_layers, drop_rate=0):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.rnn = nn.RNN(num_features, hidden_size, num_layers, batch_first=True, dropout=drop_rate, nonlinearity='relu')\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        out, _ = self.rnn(x, h0.detach())\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, num_features, output_size, hidden_size, num_layers, drop_rate=0):\n",
    "        super(SimpleLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(num_features, hidden_size, num_layers, dropout=drop_rate, batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def _initialize_weights(self, num_features):\n",
    "        # According to the paper, https://arxiv.org/pdf/1912.10454\n",
    "        #   we want to preserve the variance through layers.\n",
    "        # As a simplified approach:\n",
    "        # - Set all biases to zero\n",
    "        # - Initialize input-to-hidden weights with a variance ~ 1/N, where N is the number of features\n",
    "        # - Initialize hidden-to-hidden weights orthogonally or with a small variance\n",
    "        \n",
    "        for name, param in self.lstm.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.zeros_(param)\n",
    "            elif 'weight_ih' in name:\n",
    "                # Input to hidden weights: normal with std ~ 1/sqrt(num_features)\n",
    "                nn.init.normal_(param, mean=0.0, std=(1.0 / np.sqrt(num_features)))\n",
    "            elif 'weight_hh' in name:\n",
    "                # Hidden to hidden weights: orthogonal initialization can help stability\n",
    "                nn.init.orthogonal_(param)\n",
    "\n",
    "        # For the fully connected layer\n",
    "        nn.init.zeros_(self.fc.bias)\n",
    "        # Xavier is a reasonable choice for the final layer\n",
    "        nn.init.xavier_normal_(self.fc.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class SimpleGRU(nn.Module):\n",
    "    def __init__(self, num_features, output_size, hidden_size, num_layers, drop_rate=0):\n",
    "        super(SimpleGRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.gru = nn.GRU(num_features, hidden_size, num_layers, dropout=drop_rate, batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        out, _ = self.gru(x, h0)\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.amp import GradScaler, autocast\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_metrics(real_values, predictions): \n",
    "    ''' \n",
    "    Calculate evaluation metrics: MAE, MAPE, and R-squared. \n",
    "\n",
    "    Parameters \n",
    "    ---------- \n",
    "\n",
    "    real_values (array-like): The actual values. \n",
    "    predictions (array-like): The predicted values. \n",
    "\n",
    "    Returns \n",
    "    ------- \n",
    "    mae, mape, r_squared\n",
    "    ''' \n",
    "\n",
    "    real_values = np.array(real_values) \n",
    "    predictions = np.array(predictions) \n",
    "\n",
    "    # Mean Absolute Error (MAE) \n",
    "    mae = np.mean(np.abs(real_values - predictions)) \n",
    "\n",
    "    # Mean Absolute Percentage Error (MAPE) \n",
    "    epsilon = 1e-6\n",
    "    mape = np.mean(np.abs((real_values - predictions) / (real_values + epsilon))) * 100\n",
    "\n",
    "    # R-squared \n",
    "    ss_res = np.sum((real_values - predictions) ** 2) \n",
    "    ss_tot = np.sum((real_values - np.mean(real_values)) ** 2) \n",
    "    r_squared = 1 - (ss_res / ss_tot)\n",
    "\n",
    "    return mae, mape, r_squared\n",
    "\n",
    "def model_evaluation(model, criterion, data_loader, device='cpu'):\n",
    "\n",
    "    batch_losses = []\n",
    "\n",
    "    model.eval() # switch to evalution mode\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            batch_losses.append(loss.item())\n",
    "\n",
    "    model.train() # switch to training mode\n",
    "\n",
    "    loss_mean = np.mean(batch_losses)\n",
    "\n",
    "    return loss_mean\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, criterion, train_loader, test_loader, verbose=False, scheduler=None, device='cpu', save_model=None, save_as='model.pt'):\n",
    "    '''\n",
    "    Set `verbose=True` to see scores for each epoch. If cuda is available, set `device='cuda'`.\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    - train_losses (list): history of training loss\n",
    "    - test_losses (list): history of test/validation loss\n",
    "    '''\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    min_test_loss = float('inf')\n",
    "    for n in range(n_epochs):\n",
    "        for x_batch, y_batch in train_loader:\n",
    "\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            with autocast(device_type='cuda', dtype=torch.float16):\n",
    "                outputs = model(x_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        \n",
    "        if scheduler != None:\n",
    "            scheduler.step() # update learning rate\n",
    "        \n",
    "        train_loss = model_evaluation(model, criterion, train_loader, device=device)\n",
    "        test_loss = model_evaluation(model, criterion, test_loader, device=device)\n",
    "\n",
    "        # save model with lowest test/validation loss\n",
    "        if test_loss < min_test_loss:\n",
    "            min_test_loss = test_loss\n",
    "            if save_model == 'best':\n",
    "                torch.save(model.state_dict(), save_as)\n",
    "\n",
    "        # save model at last epoch\n",
    "        if save_model == 'last' and n == n_epochs - 1:\n",
    "            torch.save(model.state_dict(), save_as)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "        if ((n + 1) % 10 == 0) or verbose:\n",
    "            print(f'Epoch {n + 1}/{n_epochs}: Training loss {train_loss:.4f}, Validation Loss {test_loss:.4f}')\n",
    "            if scheduler != None:\n",
    "                print(f\"Current learning rate is {scheduler.get_last_lr()[0]}\")\n",
    "            print('----------------------------------------------------------')\n",
    "\n",
    "    return train_losses, test_losses\n",
    "\n",
    "def plot_metrics(train_metrics, test_metrics, metric_name):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    epochs = np.arange(len(train_metrics))\n",
    "\n",
    "    plt.plot(epochs, train_metrics, label=f'Train {metric_name}', color='blue')\n",
    "    plt.plot(epochs, test_metrics, label=f'Test {metric_name}', color='red')\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(metric_name)\n",
    "    plt.title(f'{metric_name} over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 8  # Number of features\n",
    "output_size = 288\n",
    "hidden_size = 2048 # number of hidden units\n",
    "num_layers = 3 # number of hidden layers\n",
    "num_epochs = 2\n",
    "drop_rate = 0.1\n",
    "lr_rate = 1e-4\n",
    "weight_decay = 1e-4\n",
    "scheduler = None\n",
    "\n",
    "# rnn_model = SimpleRNN(num_features, output_size, hidden_size, num_layers, drop_rate=drop_rate).to('cuda')\n",
    "# criterion = nn.MSELoss()\n",
    "# optimizer = torch.optim.Adam(rnn_model.parameters(), lr=lr_rate, weight_decay=weight_decay, fused=True)\n",
    "# scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "# train_losses, val_losses = training_loop(\n",
    "#     num_epochs, \n",
    "#     optimizer, \n",
    "#     rnn_model, \n",
    "#     criterion, \n",
    "#     train_loader, \n",
    "#     test_loader, \n",
    "#     verbose=True, \n",
    "#     scheduler=scheduler,\n",
    "#     device='cuda', \n",
    "#     save_model='last', \n",
    "#     save_as='RNN.pt'\n",
    "# )\n",
    "# plot_metrics(train_losses, val_losses, 'Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = SimpleLSTM(num_features, output_size, hidden_size, num_layers, drop_rate=drop_rate).to('cuda')\n",
    "criterion = nn.HuberLoss()\n",
    "optimizer = torch.optim.RMSprop(lstm_model.parameters(), lr=lr_rate, weight_decay=weight_decay)\n",
    "# scheduler = StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "scheduler = None\n",
    "\n",
    "train_losses, val_losses = training_loop(\n",
    "    num_epochs, \n",
    "    optimizer, \n",
    "    lstm_model, \n",
    "    criterion, \n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    verbose=True, \n",
    "    scheduler=scheduler,\n",
    "    device='cuda', \n",
    "    save_model='last', \n",
    "    save_as='LSTM.pt'\n",
    ")\n",
    "plot_metrics(train_losses, val_losses, 'Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model = SimpleGRU(num_features, output_size, hidden_size, num_layers).to('cuda')\n",
    "criterion = nn.HuberLoss()\n",
    "optimizer = torch.optim.RMSprop(gru_model.parameters(), lr=lr_rate, weight_decay=weight_decay)\n",
    "# scheduler = StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "\n",
    "train_losses, val_losses = training_loop(\n",
    "    num_epochs, \n",
    "    optimizer, \n",
    "    gru_model, \n",
    "    criterion, \n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    verbose=True, \n",
    "    scheduler=scheduler,\n",
    "    device='cuda', \n",
    "    save_model='last',\n",
    "    save_as='GRU.pt'\n",
    ")\n",
    "plot_metrics(train_losses, val_losses, 'Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def make_predictions(model, test_data, device='cuda'):\n",
    "    \"\"\"\n",
    "    Evaluate the model on test_data for the year 2020 and produce 1D arrays of predictions and actuals.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : torch.nn.Module\n",
    "        The trained model that takes an input of shape [1, 288, 7] and outputs [1, 288].\n",
    "    test_data : torch.Tensor\n",
    "        A tensor of shape [N, 7] containing continuous test data.\n",
    "        The columns are [load, temp, is_workday, year, month, day, hour].\n",
    "        Assume test_data is normalized/processed the same way as the training data.\n",
    "    device : str, optional\n",
    "        Device to run computations on ('cuda' or 'cpu'), by default 'cuda'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    predictions : np.ndarray\n",
    "        1D array containing the model's predicted load values for all predicted timesteps.\n",
    "    actuals : np.ndarray\n",
    "        1D array containing the actual load values for the corresponding timesteps.\n",
    "    \"\"\"\n",
    "\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    total_steps = test_data.shape[0]\n",
    "    # Each prediction uses 288 steps as input and predicts the next 288 steps.\n",
    "    # Need at least 288 steps beyond the input window for a full prediction.\n",
    "    max_start = total_steps - 288 * 2\n",
    "    if max_start < 0:\n",
    "        raise ValueError(\"Not enough test data to form a single input-output pair.\")\n",
    "\n",
    "    all_predictions = []\n",
    "    all_actuals = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Slide over test_data in increments of 288 steps (e.g., one day at a time, if 288 steps = one day)\n",
    "        for start_idx in range(0, max_start + 1, 288):\n",
    "            # Extract input sequence\n",
    "            input_seq = test_data[start_idx : start_idx+288]  # [288, 7]\n",
    "            input_seq = input_seq.unsqueeze(0).to(device)     # [1, 288, 7]\n",
    "\n",
    "            # Run the model\n",
    "            pred = model(input_seq)         # [1, 288]\n",
    "            pred = pred.squeeze(0).cpu().numpy()  # [288]\n",
    "\n",
    "            # Actual load for the next 288 steps\n",
    "            target_seq = test_data[start_idx+288 : start_idx+576, 0].cpu().numpy()  # [288]\n",
    "\n",
    "            # Collect results\n",
    "            all_predictions.append(pred)\n",
    "            all_actuals.append(target_seq)\n",
    "\n",
    "    # Convert to arrays of shape [M, 288]\n",
    "    all_predictions = np.array(all_predictions)  # [M, 288]\n",
    "    all_actuals = np.array(all_actuals)          # [M, 288]\n",
    "\n",
    "    # Flatten to 1D arrays\n",
    "    predictions = all_predictions.flatten()  # 1D array\n",
    "    actuals = all_actuals.flatten()          # 1D array\n",
    "\n",
    "    return predictions, actuals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved models\n",
    "\n",
    "# lstm_model = SimpleLSTM(num_features, output_size, hidden_size, num_layers).to('cuda')\n",
    "# lstm_model.load_state_dict(torch.load('LSTM.pt', weights_only=True))\n",
    "# lstm_model.eval()\n",
    "\n",
    "# gru_model = SimpleGRU(num_features, output_size, hidden_size, num_layers).to('cuda')\n",
    "# gru_model.load_state_dict(torch.load('GRU.pt', weights_only=True))\n",
    "# gru_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on 2023 validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2023\n",
    "df_val_raw = pd.read_csv(f'../data/Prepared data/{year}_features.csv')\n",
    "df_val = df_val_raw[['timestamp', 'load', 'temp', 'year', 'month', 'day', 'hour', 'minute']].copy()\n",
    "del df_val_raw\n",
    "df_val = preprocessor.transform(df_val)\n",
    "df_val = df_val.drop('timestamp', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_np = df.iloc[:288].to_numpy(dtype=np.float32)\n",
    "# initial_tensor = torch.tensor(initial_np, dtype=torch.float32)\n",
    "test_np = df_val.to_numpy(dtype=np.float32)\n",
    "test_tensor = torch.tensor(test_np, dtype=torch.float32)\n",
    "\n",
    "# predictions_rnn, actual = make_predictions(rnn_model, test_tensor, device='cuda')\n",
    "predictions_lstm, actual = make_predictions(lstm_model, test_tensor, device='cuda')\n",
    "predictions_gru, _ = make_predictions(gru_model, test_tensor, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# rnn_scores = evaluate_metrics(actual, predictions_rnn)\n",
    "# print(f'RNN: MAE {rnn_scores[0]}, MAPE {rnn_scores[1]}, R^2 {rnn_scores[2]}')\n",
    "lstm_scores = evaluate_metrics(actual, predictions_lstm)\n",
    "print(f'LSTM: MAE {lstm_scores[0]}, MAPE {lstm_scores[1]}, R^2 {lstm_scores[2]}')\n",
    "gru_scores = evaluate_metrics(actual, predictions_gru)\n",
    "print(f'GRU: MAE {gru_scores[0]}, MAPE {gru_scores[1]}, R^2 {gru_scores[2]}')\n",
    "\n",
    "time_interval = pd.date_range(start=f\"{year}-01-02\", periods=len(actual), freq='5min')\n",
    "plt.figure(figsize=(40,10))\n",
    "plt.plot(time_interval, actual, label='Actual')\n",
    "# plt.plot(time_interval, predictions_rnn, label='Predicted (RNN)')\n",
    "plt.plot(time_interval, predictions_lstm, label='Predicted (LSTM)')\n",
    "plt.plot(time_interval, predictions_gru, label='Predicted (GRU)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Load')\n",
    "plt.title('Actual & Predicted Loads over Time')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
